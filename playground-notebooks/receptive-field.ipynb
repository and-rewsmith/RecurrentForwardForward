{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvWithoutSharing(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super(ConvWithoutSharing, self).__init__()\n",
    "\n",
    "        # Calculate the size of the output and the number of weights needed\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.output_size = (kernel_size * kernel_size * in_channels, out_channels)\n",
    "        self.fc = nn.Linear(*self.output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Use the unfold method to create a view of the input where each receptive field becomes a row in a 2D matrix\n",
    "        unfolded_x = x.unfold(2, self.kernel_size, self.stride).unfold(3, self.kernel_size, self.stride)\n",
    "        unfolded_x = unfolded_x.contiguous().view(-1, self.kernel_size * self.kernel_size * self.in_channels)\n",
    "\n",
    "        # Apply the fully connected layer\n",
    "        output = self.fc(unfolded_x)\n",
    "        output = output.view(-1, self.out_channels, x.shape[2] - self.kernel_size + 1, x.shape[3] - self.kernel_size + 1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights of dims:  (4, 2)\n",
      "unfolded dims:  torch.Size([1, 1, 3, 3, 2, 2])\n",
      "unfolded dims:  torch.Size([9, 4])\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 2\n",
    "in_channels = 1\n",
    "out_channels = 2\n",
    "stride = 1\n",
    "output_size = (kernel_size *kernel_size * in_channels, out_channels)\n",
    "print(\"weights of dims: \", output_size)\n",
    "weights = nn.Linear(*output_size)\n",
    "\n",
    "batch_size = 1\n",
    "input_dim = 5\n",
    "example_tensor = torch.randn(batch_size, in_channels, 4, 4)\n",
    "unfolded = example_tensor.unfold(2, kernel_size, stride).unfold(3, kernel_size, stride)\n",
    "# [batch_size, in_channels, kernel_size, kernel_size, output_size, output_size]\n",
    "print(\"unfolded dims: \", unfolded.shape)\n",
    "unfolded = unfolded.contiguous().view(-1, kernel_size * kernel_size * in_channels)\n",
    "# [flattened other dims, flattened output]\n",
    "print(\"unfolded dims: \", unfolded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4, 4])\n",
      "tensor([[[[-0.9946, -0.4071, -0.9955, -0.4921],\n",
      "          [ 0.3420, -0.9385, -0.3527,  0.8769],\n",
      "          [-0.1706,  0.0570,  0.4960,  0.0404],\n",
      "          [-0.3765,  0.3728,  0.3542,  0.2269]],\n",
      "\n",
      "         [[-0.1993, -0.5132,  0.2181,  0.6789],\n",
      "          [ 0.6060, -0.7805, -0.4876, -1.1001],\n",
      "          [ 0.8882,  0.7053, -0.4613,  0.7275],\n",
      "          [ 0.6015,  0.5583,  0.2537, -1.0038]],\n",
      "\n",
      "         [[-0.4446,  0.1035, -0.4651, -0.0029],\n",
      "          [-0.1907, -1.0302, -1.1328,  0.1075],\n",
      "          [-0.0401,  0.4906, -0.9713, -0.8414],\n",
      "          [-0.4314,  0.5927,  0.4548,  0.4047]]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "in_channels = 2\n",
    "out_channels = 3\n",
    "kernel_size = 2\n",
    "stride = 1\n",
    "c = ConvWithoutSharing(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "# [batch, in_channels, height, width]\n",
    "example_tensor = torch.randn(1, 2, 5, 5)\n",
    "out = c.forward(example_tensor)\n",
    "# [batch, out channels, fittable, fittable]\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO what is peer normalization?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94486aeb2216c8860b0e8bc0835934629c340875e758c5c4e680b988c4ee5423"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
