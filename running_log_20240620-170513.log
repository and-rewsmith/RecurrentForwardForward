Sweep logs. Current datetime: Thu Jun 20 17:05:13 2024

    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 8, 'loss_threshold': 1.5, 'damping_factor': 0.5150576391390443, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.7052787895004816, 'loss_scale_predictive': 0.8674186859696718, 'loss_scale_hebbian': 0.4524021563741142, 'loss_scale_decorrelative': 0.5958658741502516, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.04870816512041998, 'learning_rate': 0.0003479715760266484}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 16, 'dataset': 'MNIST'}}
    Seed: 1310
---------------------------------
    train_accuracy: 10.0
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 8, 'loss_threshold': 1.5, 'damping_factor': 0.5150576391390443, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.7052787895004816, 'loss_scale_predictive': 0.8674186859696718, 'loss_scale_hebbian': 0.4524021563741142, 'loss_scale_decorrelative': 0.5958658741502516, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.04870816512041998, 'learning_rate': 0.0003479715760266484}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 16, 'dataset': 'MNIST'}}
    train_accuracy: 10.0

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 7, 'loss_threshold': 1.5, 'damping_factor': 0.48485738404418177, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.9031607023977796, 'loss_scale_predictive': 0.3929542609768376, 'loss_scale_hebbian': 0.7750150959823688, 'loss_scale_decorrelative': 0.5677365927008764, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.8104549359294553, 'learning_rate': 0.0003776373176494736}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 18, 'dataset': 'MNIST'}}
    Seed: 8899
---------------------------------
    train_accuracy: 11.4
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 7, 'loss_threshold': 1.5, 'damping_factor': 0.48485738404418177, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.9031607023977796, 'loss_scale_predictive': 0.3929542609768376, 'loss_scale_hebbian': 0.7750150959823688, 'loss_scale_decorrelative': 0.5677365927008764, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.8104549359294553, 'learning_rate': 0.0003776373176494736}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 18, 'dataset': 'MNIST'}}
    train_accuracy: 11.4

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 4, 'loss_threshold': 1.5, 'damping_factor': 0.837239122484414, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.8930591399233534, 'loss_scale_predictive': 0.5239174745125965, 'loss_scale_hebbian': 0.9176727224598, 'loss_scale_decorrelative': 0.5243585926512571, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.31600554415657434, 'learning_rate': 0.0003894236376165262}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 18, 'dataset': 'MNIST'}}
    Seed: 5787
---------------------------------
    train_accuracy: 10.4
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 4, 'loss_threshold': 1.5, 'damping_factor': 0.837239122484414, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.8930591399233534, 'loss_scale_predictive': 0.5239174745125965, 'loss_scale_hebbian': 0.9176727224598, 'loss_scale_decorrelative': 0.5243585926512571, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.31600554415657434, 'learning_rate': 0.0003894236376165262}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 18, 'dataset': 'MNIST'}}
    train_accuracy: 10.4

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 7, 'loss_threshold': 1.5, 'damping_factor': 0.7074559417343583, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.4135479046923093, 'loss_scale_predictive': 0.6512598091971263, 'loss_scale_hebbian': 0.25635160104102284, 'loss_scale_decorrelative': 0.7527225760106392, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.3882941324297575, 'learning_rate': 4.469871093948364e-05}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 15, 'dataset': 'MNIST'}}
    Seed: 2320
---------------------------------
    train_accuracy: 11.799999999999999
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 7, 'loss_threshold': 1.5, 'damping_factor': 0.7074559417343583, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.4135479046923093, 'loss_scale_predictive': 0.6512598091971263, 'loss_scale_hebbian': 0.25635160104102284, 'loss_scale_decorrelative': 0.7527225760106392, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.3882941324297575, 'learning_rate': 4.469871093948364e-05}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 15, 'dataset': 'MNIST'}}
    train_accuracy: 11.799999999999999

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 5, 'loss_threshold': 1.5, 'damping_factor': 0.17159428882209254, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.4451750177367505, 'loss_scale_predictive': 0.1669974982630107, 'loss_scale_hebbian': 0.19797330493125945, 'loss_scale_decorrelative': 0.07761184481840866, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.18075620934532455, 'learning_rate': 1.1729343260700018e-06}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 11, 'dataset': 'MNIST'}}
    Seed: 7911
---------------------------------
    train_accuracy: 11.0
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 5, 'loss_threshold': 1.5, 'damping_factor': 0.17159428882209254, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.4451750177367505, 'loss_scale_predictive': 0.1669974982630107, 'loss_scale_hebbian': 0.19797330493125945, 'loss_scale_decorrelative': 0.07761184481840866, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.18075620934532455, 'learning_rate': 1.1729343260700018e-06}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 11, 'dataset': 'MNIST'}}
    train_accuracy: 11.0

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 8, 'loss_threshold': 1.5, 'damping_factor': 0.3289021203445148, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.21030930509782353, 'loss_scale_predictive': 0.47248040495949295, 'loss_scale_hebbian': 0.5338830434545542, 'loss_scale_decorrelative': 0.07724739322731577, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.6177926843110754, 'learning_rate': 0.00033371080662919587}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 17, 'dataset': 'MNIST'}}
    Seed: 7001
---------------------------------
    train_accuracy: 9.2
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 8, 'loss_threshold': 1.5, 'damping_factor': 0.3289021203445148, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.21030930509782353, 'loss_scale_predictive': 0.47248040495949295, 'loss_scale_hebbian': 0.5338830434545542, 'loss_scale_decorrelative': 0.07724739322731577, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.6177926843110754, 'learning_rate': 0.00033371080662919587}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 17, 'dataset': 'MNIST'}}
    train_accuracy: 9.2

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 7, 'loss_threshold': 1.5, 'damping_factor': 0.12098243894143774, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.007527355186462525, 'loss_scale_predictive': 0.927257554308428, 'loss_scale_hebbian': 0.9454139222185374, 'loss_scale_decorrelative': 0.8690051821267942, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.14633838950919287, 'learning_rate': 0.0002623422396947769}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 15, 'dataset': 'MNIST'}}
    Seed: 7093
---------------------------------
    train_accuracy: 8.799999999999999
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 7, 'loss_threshold': 1.5, 'damping_factor': 0.12098243894143774, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.007527355186462525, 'loss_scale_predictive': 0.927257554308428, 'loss_scale_hebbian': 0.9454139222185374, 'loss_scale_decorrelative': 0.8690051821267942, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.14633838950919287, 'learning_rate': 0.0002623422396947769}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 15, 'dataset': 'MNIST'}}
    train_accuracy: 8.799999999999999

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 9, 'loss_threshold': 1.5, 'damping_factor': 0.6036587843546937, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.3854507466214181, 'loss_scale_predictive': 0.17939679854876145, 'loss_scale_hebbian': 0.33422347968116484, 'loss_scale_decorrelative': 0.5125816291343509, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.26619375476619156, 'learning_rate': 7.205528375285338e-05}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 13, 'dataset': 'MNIST'}}
    Seed: 4783
---------------------------------
    train_accuracy: 9.4
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 9, 'loss_threshold': 1.5, 'damping_factor': 0.6036587843546937, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.3854507466214181, 'loss_scale_predictive': 0.17939679854876145, 'loss_scale_hebbian': 0.33422347968116484, 'loss_scale_decorrelative': 0.5125816291343509, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.26619375476619156, 'learning_rate': 7.205528375285338e-05}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 13, 'dataset': 'MNIST'}}
    train_accuracy: 9.4

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 4, 'loss_threshold': 1.5, 'damping_factor': 0.31270372191970247, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.7884664120187628, 'loss_scale_predictive': 0.939085990297198, 'loss_scale_hebbian': 0.32608633351452165, 'loss_scale_decorrelative': 0.3257021679652963, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.19257033753436947, 'learning_rate': 0.0004851666321550113}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 11, 'dataset': 'MNIST'}}
    Seed: 5076
---------------------------------
    train_accuracy: 7.6
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 4, 'loss_threshold': 1.5, 'damping_factor': 0.31270372191970247, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.7884664120187628, 'loss_scale_predictive': 0.939085990297198, 'loss_scale_hebbian': 0.32608633351452165, 'loss_scale_decorrelative': 0.3257021679652963, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.19257033753436947, 'learning_rate': 0.0004851666321550113}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 11, 'dataset': 'MNIST'}}
    train_accuracy: 7.6

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 8, 'loss_threshold': 1.5, 'damping_factor': 0.2591536201607729, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.20538689454956527, 'loss_scale_predictive': 0.2108907708213149, 'loss_scale_hebbian': 0.9723531892951056, 'loss_scale_decorrelative': 0.23501560780538863, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.8853415593286836, 'learning_rate': 0.00011745025048048916}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 18, 'dataset': 'MNIST'}}
    Seed: 3705
---------------------------------
    train_accuracy: 8.6
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 8, 'loss_threshold': 1.5, 'damping_factor': 0.2591536201607729, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.20538689454956527, 'loss_scale_predictive': 0.2108907708213149, 'loss_scale_hebbian': 0.9723531892951056, 'loss_scale_decorrelative': 0.23501560780538863, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.8853415593286836, 'learning_rate': 0.00011745025048048916}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 18, 'dataset': 'MNIST'}}
    train_accuracy: 8.6

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 10, 'loss_threshold': 1.5, 'damping_factor': 0.27604487210472406, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.3517188107981587, 'loss_scale_predictive': 0.7524883234902953, 'loss_scale_hebbian': 0.635995513609041, 'loss_scale_decorrelative': 0.9279595068108808, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.352172973451214, 'learning_rate': 0.00030265814245793496}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 16, 'dataset': 'MNIST'}}
    Seed: 7090
---------------------------------
    train_accuracy: 11.600000000000001
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 10, 'loss_threshold': 1.5, 'damping_factor': 0.27604487210472406, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.3517188107981587, 'loss_scale_predictive': 0.7524883234902953, 'loss_scale_hebbian': 0.635995513609041, 'loss_scale_decorrelative': 0.9279595068108808, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.352172973451214, 'learning_rate': 0.00030265814245793496}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 16, 'dataset': 'MNIST'}}
    train_accuracy: 11.600000000000001

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 4, 'loss_threshold': 1.5, 'damping_factor': 0.2956038826108043, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.008441291527650385, 'loss_scale_predictive': 0.9297720711561224, 'loss_scale_hebbian': 0.5337013274951498, 'loss_scale_decorrelative': 0.9243826378585364, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.7384086013231369, 'learning_rate': 0.0002676740515719335}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 11, 'dataset': 'MNIST'}}
    Seed: 5147
---------------------------------
    train_accuracy: 10.4
    ---------------------------------
    
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 4, 'loss_threshold': 1.5, 'damping_factor': 0.2956038826108043, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.008441291527650385, 'loss_scale_predictive': 0.9297720711561224, 'loss_scale_hebbian': 0.5337013274951498, 'loss_scale_decorrelative': 0.9243826378585364, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.7384086013231369, 'learning_rate': 0.0002676740515719335}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 11, 'dataset': 'MNIST'}}
    train_accuracy: 10.4

======================================                =========================================
    running with:
    settings: {'model': {'hidden_sizes': [100, 100, 100, 100, 100], 'epochs': 25, 'prelabel_timesteps': 4, 'loss_threshold': 1.5, 'damping_factor': 0.2956038826108043, 'epsilon': 1e-08, 'skip_profiling': True, 'should_log_metrics': True, 'should_replace_neg_data': False, 'should_load_weights': False, 'dropout': 0.0, 'loss_scale_ff': 0.008441291527650385, 'loss_scale_predictive': 0.9297720711561224, 'loss_scale_hebbian': 0.5337013274951498, 'loss_scale_decorrelative': 0.9243826378585364, 'lr_step_size': 10000, 'lr_gamma': 0.9, 'ff_activation': 'relu', 'ff_optimizer': 'rmsprop', 'ff_rmsprop': {'momentum': 0.7384086013231369, 'learning_rate': 0.0002676740515719335}, 'ff_adam': {'learning_rate': 1e-05}, 'ff_adadelta': {'learning_rate': 0.0001}, 'classifier_optimizer': 'adam', 'classifier_rmsprop': {'momentum': 0.0, 'learning_rate': 1e-05}, 'classifier_adam': {'learning_rate': 0.01}, 'classifier_adadelta': {'learning_rate': 1e-05}}, 'device': {'device': 'mps'}, 'data_config': {'data_size': 784, 'num_classes': 10, 'train_batch_size': 500, 'test_batch_size': 500, 'iterations': 11, 'dataset': 'MNIST'}}
    Seed: 1879
